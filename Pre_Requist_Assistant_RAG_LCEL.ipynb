{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519ff36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a55e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "print(LANGSMITH_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852dd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478883a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model = \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf599f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye take care yourself\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question  = input(\"type your question. if you want to quit the chat write quit\")\n",
    "    if question !=\"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"goodbye take care yourself\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d59d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa4c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69be7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0284b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d25eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9389db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Vibhav Ahuja, it's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke(('Hi I am Vibhav Ahuja'), config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a48371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi I am Vibhav Ahuja', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Vibhav Ahuja, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 43, 'total_tokens': 73, 'completion_time': 0.109090909, 'prompt_time': 0.001944977, 'queue_time': 0.054855403, 'total_time': 0.111035886}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None}, id='run--3594b7c4-2d38-4a0f-8e1b-f3de6bf15ee9-0', usage_metadata={'input_tokens': 43, 'output_tokens': 30, 'total_tokens': 73})])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "299758fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Vibhav Ahuja.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke(('what is my name'), config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c9886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ai Agents\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# embedding = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs={\"device\": \"cpu\"})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6f727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc133626",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2899200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '..\\\\data\\\\Generic Modular RAG Documentation.txt'}, page_content=\"ï»¿Generic Modular RAG Documentation\\n\\n\\nOverview\\nGeneric Modular RAG (Retrieval-Augmented Generation) is a flexible and adaptable framework designed for efficient information retrieval and generation across various data formats and domains. It provides a plug-and-play architecture where individual components such as document loaders, chunkers, retrievers, vector stores, LLMs, and re-rankers can be integrated and customized as needed.\\nKey features:\\n* Modular design for easy customization and extension.\\n* Compatibility with diverse file types and formats.\\n* Scalable for both small-scale and enterprise-level applications.\\n* Enables explainable and traceable outputs suitable for production environments.\\nStep 1: Data Preprocessing & File Extraction\\nTo begin with, preprocess and extract content from various file types including .txt, .pdf, .csv, .xlsx, and .docx. Below are the recommended Python libraries for each format:\\nFile Format\\n\\tRecommended Libraries\\n\\t                 TXT\\n\\t                                      built-in open(), pathlib\\n\\t                 PDF\\n\\t                                      PyMuPDF (fitz), PyPDF2, pdfminer.six\\n\\t                 CSV\\n\\t                                      pandas (pd.read_csv)\\n\\t                XLSX\\n\\t                                      pandas (pd.read_excel), openpyxl\\n\\t                DOCX\\n\\t                                      python-docx\\n\\tThese libraries enable robust extraction of text data, forming the foundation for further processing such as chunking, embedding, and retrieval in the RAG pipeline.\\nStep 2: Embedding\\nAfter text extraction, the next step is to convert the textual data into vector representations using embedding models. The text is first split into manageable chunks using a sliding window approach, which includes two key parameters:\\n* chunk_size: the number of tokens/words per chunk.\\n* chunk_overlap: the number of overlapping tokens between consecutive chunks.\\nGiven the variability of input documents, choosing the optimal chunk_size and chunk_overlap will require iterative experimentation.\\nFor embeddings, a variety of models can be used, including:\\n* All-MiniLM (e.g., sentence-transformers/all-MiniLM-L6-v2)\\n* Other open-source embedding models available via Hugging Face or local model stores\\nThese embeddings provide the basis for semantic search and retrieval in downstream RAG tasks.\\nStep 3: Vector Store & Metadata Storage\\nOnce embeddings are generated, they are stored in a vector database for efficient similarity search. In this setup:\\n* Embeddings are stored in Milvus (a high-performance vector database)\\n* Raw or processed text and metadata are stored in PostgreSQL for relational querying and context retrieval\\nFor Milvus, we will experiment with different Similarity Metrics and Index Types to optimize retrieval performance. These include:\\nSimilarity Metrics\\n* Euclidean (L2 distance)\\n* Inner Product (IP)\\n* Cosine Similarity\\nIndex Types\\n* IVF_FLAT\\n* IVF_SQ8\\n* IVF_PQ\\n* HNSW (Hierarchical Navigable Small World)\\n* ANNOY (Approximate Nearest Neighbors Oh Yeah)\\n\\n\\nThe optimal choice depends on data characteristics, use case requirements, and latency constraints. This phase is experimental to find the best configuration for our data.\\nTo monitor and manage vector data in Milvus, we will use Attu â€” a graphical user interface for Milvus that supports inspection, querying, and monitoring of collections and indexes.\\nStep 4: Open Source LLMs and Ollama\\nThis step involves integrating a large language model (LLM) to generate answers based on retrieved context. We utilize open-source LLMs for flexibility and cost efficiency. These models can be served locally using Ollama, which simplifies deployment and usage.\\nExamples of open-source LLMs:\\n* Mistral\\n* LLaMA 2\\nOllama provides a fast and containerized interface to run these models efficiently on local machines.\\nStep 5: Retrieval\\nRetrieval is the core step in RAG where relevant chunks are fetched based on the user's query using vector similarity. Three main types of retrieval approaches are:\\n1. Sparse Retrieval (e.g., BM25)\\n2. Dense Retrieval (e.g., using embeddings and vector stores)\\n3. Hybrid Retrieval (combining sparse and dense)\\nThese methods help extract the most relevant passages to pass as context to the LLM.\\nStep 6: Reranking & Hybrid Search\\nReranking is the process of refining retrieved documents based on relevance scores. It helps prioritize better responses from the retrieved context.\\nTypes of Reranking:\\n* Embedding-based (using cosine similarity again)\\n* Cross-Encoder-based (using deep models like BERT for scoring query-document pairs)\\n* Add other types of re ranking as well\\nHybrid search combines both sparse and dense retrieval methods, and reranking is often applied after this to fine-tune the results.\\nStep 7: Response & History Management\\nAfter generating the response using the LLM, the query-response pairs along with relevant metadata (timestamp, user ID, session ID, etc.) are stored in Redis. Redis provides fast in-memory storage, making it ideal for maintaining chat history and real-time analytics.\")]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8884910",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea2a5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(new_docs, embedding)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9a0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "060d31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    RunnableParallel({'context': retriever, 'question': RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa775634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here are 3 points about Generation (referred to as \"Gen AI\"):\n",
      "\n",
      "1. **Flexible framework**: Generation is described as a \"flexible and adaptable framework\".\n",
      "2. **Part of a larger architecture**: It is mentioned in the context of a \"plug-and-play architecture\", suggesting that Generation is a component of a larger system.\n",
      "3. **Related to Modular RAG**: The mentions of Generation and other concepts (e.g., Milvus, Overview) are all sourced from the \"Generic Modular RAG Documentation.txt\", implying a connection between Generation and Modular RAG.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is gen ai? give me 3 points\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87f1f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eea02320",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "037d8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "564cccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a11be86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis a\n"
     ]
    }
   ],
   "source": [
    "print(tool.run({'query':'langchain'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dec1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis a\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run('langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "130e2ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ai Agents\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3672: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "410cb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query : str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0028e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(\n",
    "    name = 'wiki-tool',\n",
    "    description='look up things in wikipedia',\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cdfa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b2e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8b2ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vibhav.ahuja\\AppData\\Local\\Temp\\ipykernel_18080\\4050003858.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74fc9594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The latest on the Burning Man flooding - NPR',\n",
       "  'url': 'https://www.npr.org/2023/09/03/1197497458/the-latest-on-the-burning-man-flooding',\n",
       "  'content': \"Knee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been [...] Knee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been [...] Knee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been\",\n",
       "  'score': 0.735737},\n",
       " {'title': 'What went wrong at Burning Man 2023 - From flood chaos to ...',\n",
       "  'url': 'https://www.themirror.com/entertainment/celebrity-news/what-went-wrong-burning-man-656685',\n",
       "  'content': 'The rainfall caused [flooding](https://www.themirror.com/news/us-news/three-eyed-dinosaur-shrimp-found-85274) and muddy conditions in the dessert which left some Burners stranded and others making a grueling mass exodus by walking the many miles to get closer to civilization. That year, it was the 35th annual Burning Man and it took place from August 27- September 4, 2023. 73,000 people were estimated to have attended the festival. [...] ![Burning Man 2023](https://i2-prod.themirror.com/article658172.ece/ALTERNATES/s615b/0_US-FESTIVAL-WEATHER.jpg)\\n\\nKatie mentioned how a nearby neighbor with their RV took her in when her tent flooded and the camp came together to cook tacos for 200. There was music still playing, people dancing and some held meditation workshops for others. She also shut down the rumors about an Ebola outbreak at the site and about the man who died passing away as a result of the weather. [...] It was on Friday, September 1, when heavy rainfall from Tropical Storm Hilary fell on to Black Rock desert in Reno, Nevada where Burning Man takes place. During the annual festival, a made-man temporary settlement is constructed.',\n",
       "  'score': 0.6786044},\n",
       " {'title': \"What we know about 2023 Burning Man festival's flooding chaos\",\n",
       "  'url': 'https://www.independent.co.uk/news/world/americas/what-is-burning-man-festival-b2404911.html',\n",
       "  'content': 'Heavy rains, brought on by [a rare hurricane on the West Coast](/climate-change/news/hurricane-hilary-2023-california-b2395549.html), forced organisers and local authorities to close roads for the remainder of the festival and told anyone en route to go home.\\n\\nBy Saturday, more than 70,000 “Burners” at the site were urged to hunker down and conserve supplies amid mud slicks and unserviced toilets. [...] On Sunday, police announced an investigation into an unspecified death at the festival. The deceased was identified as 32-year-old Leon Reece - but his cause of death has not been determined. [...] The start of the counter-culture festival was met with [climate activists](/topic/climate-activists) blocking the only road leading to the site in [Nevada](/topic/nevada)’s [Black Rock Desert](/topic/black-rock-desert) before being rammed by a tribal park ranger in his patrol truck – an incident that is now under investigation.\\n\\nThen toward the end of the nine-day art and cultures festival, heavy rains poured down, causing flooding and a massive amount of mud.',\n",
       "  'score': 0.6721816},\n",
       " {'title': \"Burning Man 2023: 7 Truths and 5 Lies About This Year's Flooding\",\n",
       "  'url': 'https://sfstandard.com/2023/09/03/burning-man-2023-truths-and-lies-about-this-years-flooding/',\n",
       "  'content': 'There have been no credible reports of outbreaks of communicable illness since the rains on Friday that flooded the temporary city. Portable toilets were serviced right before the rains, and trucks were seen servicing them again on the drying playa on Sunday morning. The Pershing County Sheriff reported one death at the event, but it did not appear related to the storm.',\n",
       "  'score': 0.66621506},\n",
       " {'title': 'Burning Man flooding: What happened to stranded festivalgoers?',\n",
       "  'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331',\n",
       "  'content': \"Tens of thousands of Burning Man attendees are now able to leave the festival after a downpour and [massive flooding](https://abcnews.go.com/alerts/weather) left them stranded over the weekend.\\n\\nThe festival, held in the Black Rock Desert in northwestern Nevada, was attended by more than 70,000 people last year, and just as many were expected this year. Burning Man began on Aug. 28 and was scheduled to run through Sept. 4. [...] One person [died at the festival](https://abcnews.go.com/US/burning-man-rains-mud/story?id=102886032) amid the unusual weather conditions, the Pershing County Sheriff's Office confirmed Sunday morning in a statement. The death is under investigation.\",\n",
       "  'score': 0.6643884}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\": \"What happened in the latest burning man floods\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e6d29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an assistant.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "581dd2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B14EA89620>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B14EA89620>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': [], 'instructions': 'You are an assistant.'} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'openai-functions-template', 'lc_hub_commit_hash': 'b4198088b0f11cbe911a9e1cb6546893c00283b6cf0f80ae003b3955efdfe281'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], input_types={}, partial_variables={}, template='{instructions}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6749397",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebefc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bea85b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))]\n"
     ]
    }
   ],
   "source": [
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9187baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f381d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acb810b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'India'}`\n",
      "responded: Here are 10 points about India:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'India - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/India', 'content': '**India**, officially the **Republic of India**,[[j]](https://en.wikipedia.org/wiki/India#cite_note-29)[[20]](https://en.wikipedia.org/wiki/India#cite_note-30) is a country in [South Asia](https://en.wikipedia.org/wiki/South_Asia \"South Asia\"). It is the [seventh-largest country by area](https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_area \"List of countries and dependencies by area\"); the [most populous [...] India has been a [federal republic](https://en.wikipedia.org/wiki/Federal_republic \"Federal republic\") since 1950, governed through a democratic [parliamentary system](https://en.wikipedia.org/wiki/Parliamentary_system \"Parliamentary system\"). It is a [pluralistic](https://en.wikipedia.org/wiki/Pluralism_(political_philosophy) \"Pluralism (political philosophy)\"), [multilingual](https://en.wikipedia.org/wiki/Multilingualism \"Multilingualism\") and [multi-ethnic [...] India is a [federation](https://en.wikipedia.org/wiki/Federation \"Federation\") with a [parliamentary system](https://en.wikipedia.org/wiki/Parliamentary_system \"Parliamentary system\") governed under the [Constitution of India](https://en.wikipedia.org/wiki/Constitution_of_India \"Constitution of India\"). [Federalism in India](https://en.wikipedia.org/wiki/Federalism_in_India \"Federalism in India\") defines the power distribution between the union and the', 'score': 0.8286204}]\u001b[0m\u001b[32;1m\u001b[1;3mHere are 10 points about India based on the tool call result:\n",
      "\n",
      "1. **Official Name**: The official name of India is the Republic of India.\n",
      "\n",
      "2. **Location**: India is a country located in South Asia.\n",
      "\n",
      "3. **Area**: India is the seventh-largest country by area.\n",
      "\n",
      "4. **Population**: India is the most populous democracy in the world.\n",
      "\n",
      "5. **Government**: India has been a federal republic since 1950, governed through a democratic parliamentary system.\n",
      "\n",
      "6. **System of Government**: India is a pluralistic, multilingual, and multi-ethnic society with a parliamentary system of government.\n",
      "\n",
      "7. **Constitution**: India is governed under the Constitution of India.\n",
      "\n",
      "8. **Federalism**: Federalism in India defines the power distribution between the union and the states.\n",
      "\n",
      "9. **Language**: India is a multilingual country, with many languages spoken across the nation.\n",
      "\n",
      "10. **Government Structure**: India is a federation with a parliamentary system of government, where power is distributed between the union and the states.\n",
      "\n",
      "Please let me know if you need further information or if you'd like me to call another tool!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'explain about india at least 10 points and give answer point wise', 'output': \"Here are 10 points about India based on the tool call result:\\n\\n1. **Official Name**: The official name of India is the Republic of India.\\n\\n2. **Location**: India is a country located in South Asia.\\n\\n3. **Area**: India is the seventh-largest country by area.\\n\\n4. **Population**: India is the most populous democracy in the world.\\n\\n5. **Government**: India has been a federal republic since 1950, governed through a democratic parliamentary system.\\n\\n6. **System of Government**: India is a pluralistic, multilingual, and multi-ethnic society with a parliamentary system of government.\\n\\n7. **Constitution**: India is governed under the Constitution of India.\\n\\n8. **Federalism**: Federalism in India defines the power distribution between the union and the states.\\n\\n9. **Language**: India is a multilingual country, with many languages spoken across the nation.\\n\\n10. **Government Structure**: India is a federation with a parliamentary system of government, where power is distributed between the union and the states.\\n\\nPlease let me know if you need further information or if you'd like me to call another tool!\"}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.invoke({\"input\": \"explain about india at least 10 points and give answer point wise\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool test: [{'title': 'India | History, Maps, Population, Economy, & Facts | Britannica', 'url': 'https://www.britannica.com/place/India', 'content': '**India**, [country](https://www.britannica.com/topic/nation-state) that occupies the greater part of [South Asia](https://www.britannica.com/place/South-Asia). It is made up of 28 states and eight [union territories](https://www.britannica.com/topic/union-territory), and its national capital is [New Delhi](https://www.britannica.com/place/New-Delhi), built in the 20th century just south of the historic hub of Old Delhi to serve as India’s administrative center. Its government is a [...] India remains one of the most ethnically diverse countries in the world. Apart from its many religions and sects, India is home to innumerable castes and tribes, as well as to more than a dozen major and hundreds of minor linguistic groups from several language families unrelated to one another. Religious minorities, including Muslims, Christians, Sikhs, Buddhists, and Jains, still account for a significant proportion of the population. Earnest attempts have been made to instill a spirit of [...] The land of India—together with Bangladesh and most of Pakistan—forms a well-defined subcontinent, set off from the rest of Asia by the [imposing](https://www.britannica.com/dictionary/imposing) northern mountain rampart of the [Himalayas](https://www.britannica.com/place/Himalayas) and by adjoining mountain ranges to the west and east. In area, India ranks as the seventh largest country in the world.', 'score': 0.6213807}, {'title': 'India - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/India', 'content': '**India**, officially the **Republic of India**,[[j]](https://en.wikipedia.org/wiki/India#cite_note-29)[[20]](https://en.wikipedia.org/wiki/India#cite_note-30) is a country in [South Asia](https://en.wikipedia.org/wiki/South_Asia \"South Asia\"). It is the [seventh-largest country by area](https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_area \"List of countries and dependencies by area\"); the [most populous [...] India is a [megadiverse country](https://en.wikipedia.org/wiki/Megadiverse_country \"Megadiverse country\"), a term employed for 17 countries that display high [biological diversity](https://en.wikipedia.org/wiki/Biological_diversity \"Biological diversity\") and contain many species exclusively [indigenous](https://en.wikipedia.org/wiki/Indigenous_(ecology) \"Indigenous (ecology)\"), or [endemic](https://en.wikipedia.org/wiki/Endemic \"Endemic\"), to [...] India has been a [federal republic](https://en.wikipedia.org/wiki/Federal_republic \"Federal republic\") since 1950, governed through a democratic [parliamentary system](https://en.wikipedia.org/wiki/Parliamentary_system \"Parliamentary system\"). It is a [pluralistic](https://en.wikipedia.org/wiki/Pluralism_(political_philosophy) \"Pluralism (political philosophy)\"), [multilingual](https://en.wikipedia.org/wiki/Multilingualism \"Multilingualism\") and [multi-ethnic', 'score': 0.57437146}]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'India'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'India - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/India', 'content': '**India**, officially the **Republic of India**,[[j]](https://en.wikipedia.org/wiki/India#cite_note-29)[[20]](https://en.wikipedia.org/wiki/India#cite_note-30) is a country in [South Asia](https://en.wikipedia.org/wiki/South_Asia \"South Asia\"). It is the [seventh-largest country by area](https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_area \"List of countries and dependencies by area\"); the [most populous [...] India has been a [federal republic](https://en.wikipedia.org/wiki/Federal_republic \"Federal republic\") since 1950, governed through a democratic [parliamentary system](https://en.wikipedia.org/wiki/Parliamentary_system \"Parliamentary system\"). It is a [pluralistic](https://en.wikipedia.org/wiki/Pluralism_(political_philosophy) \"Pluralism (political philosophy)\"), [multilingual](https://en.wikipedia.org/wiki/Multilingualism \"Multilingualism\") and [multi-ethnic [...] India is a [federation](https://en.wikipedia.org/wiki/Federation \"Federation\") with a [parliamentary system](https://en.wikipedia.org/wiki/Parliamentary_system \"Parliamentary system\") governed under the [Constitution of India](https://en.wikipedia.org/wiki/Constitution_of_India \"Constitution of India\"). [Federalism in India](https://en.wikipedia.org/wiki/Federalism_in_India \"Federalism in India\") defines the power distribution between the union and the', 'score': 0.8286204}]\u001b[0m\u001b[32;1m\u001b[1;3mIndia, officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area and the second-most populous country with over 1.3 billion people. India has been a federal republic since 1950, governed through a democratic parliamentary system. It is a pluralistic, multilingual, and multi-ethnic society. India is a federation with a parliamentary system governed under the Constitution of India. Federalism in India defines the power distribution between the union and the states.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final response: {'input': 'explain about india', 'output': 'India, officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area and the second-most populous country with over 1.3 billion people. India has been a federal republic since 1950, governed through a democratic parliamentary system. It is a pluralistic, multilingual, and multi-ethnic society. India is a federation with a parliamentary system governed under the Constitution of India. Federalism in India defines the power distribution between the union and the states.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor,  create_tool_calling_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\") \n",
    "\n",
    "tavily_tool = TavilySearchResults()\n",
    "tools = [tavily_tool]\n",
    "\n",
    "print(\"Tool test:\", tavily_tool.invoke({\"query\": \"explain about india\"}))\n",
    "\n",
    "instructions = \"You are an assistant.\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "\n",
    "agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "response = agent_executor.invoke({\"input\": \"explain about india\"})\n",
    "print(\"Final response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c596e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
